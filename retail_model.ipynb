{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will code this task in PyTorch. I will follow a traditional Machine Learning / Deep Learning pipeline. \n",
    "- Data Preparation: Cleaning and preparing data for training, validation and testing. Including the DataLoader for further training.\n",
    "- Model: Design and implementation of my Deep Learning model architecture. The DataLoader to work according to the format prepared in the Data Preparation. Lastly, a Trainer Class to perform the training of the model.\n",
    "- Evaluation: Test the model with AUC score.\n",
    "- Testing: Test on the 50th week.\n",
    "\n",
    "# TO-DO: \n",
    "- 3th cell change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm as tqdm\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from configer import Configer\n",
    "from torch.utils.data import DataLoader\n",
    "import chart_studio.plotly as py\n",
    "import plotly.offline as pyoff\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>t</th>\n",
       "      <th>price</th>\n",
       "      <th>advertised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>0.961396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9420</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.479493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14082</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>1.961365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15652</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15653</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1.961464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73342</th>\n",
       "      <td>1999</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>0.699985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73343</th>\n",
       "      <td>1999</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>1.750835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73344</th>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74968</th>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76501</th>\n",
       "      <td>1999</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>2.295451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76502 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          i   j   t     price  advertised\n",
       "4818      0  39   3  0.961396           1\n",
       "9420      0   6   6  0.479493           1\n",
       "14082     0  30   9  1.961365           0\n",
       "15652     0   6  10  0.799155           0\n",
       "15653     0  18  10  1.961464           0\n",
       "...     ...  ..  ..       ...         ...\n",
       "73342  1999   3  46  0.699985           0\n",
       "73343  1999   5  46  1.750835           0\n",
       "73344  1999   6  46  0.799155           0\n",
       "74968  1999   6  47  0.799155           0\n",
       "76501  1999  13  48  2.295451           0\n",
       "\n",
       "[76502 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "data = pd.read_csv(f\"data/csv/train.csv\").sort_values(['i','t'])\n",
    "#to numpy\n",
    "customers = data['i'].to_numpy(dtype = np.int32)\n",
    "times = data['t'].to_numpy(dtype = np.int32)\n",
    "prods = data['j'].to_numpy(dtype = np.int32)\n",
    "prices = data['price'].to_numpy(dtype = np.float32)\n",
    "advertised = data['advertised'].to_numpy(dtype = np.bool)\n",
    "#number max customers\n",
    "n_cust = data.i.max() + 1\n",
    "n_prod = data.j.max() + 1\n",
    "T = data.t.max() + 1\n",
    "#paths for saving/loading\n",
    "hist_path = 'data/csv/hist_data.npz'\n",
    "coup_path = 'data/csv/coup_data.npz'\n",
    "#skip_cells\n",
    "skip = 1\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix with the customer purchasing history (customer i purchased product j at time t) and save it with a gzip compression. It will be a matrix of dimensions [max_customers, weeks, max_products]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [04:09<00:00,  8.01it/s]\n"
     ]
    }
   ],
   "source": [
    "hist_data = np.zeros([n_cust, T, n_prod], dtype=np.bool) \n",
    "for i in tqdm(range(n_cust)):\n",
    "    for t in range(T):\n",
    "        for j in range(n_prod):\n",
    "            hist_data[i, t, j] = np.sum(prods[(customers == i) & (times == t)] == j) > 0\n",
    "\n",
    "np.savez(hist_path, data=hist_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the value of the discount recieved by coustomer i in time t for product j. Will have the same size as hist_data. Based on the original price & advertised price. (Formula: (orig_price - adv_price)/ orig_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:07<00:00, 276.77it/s]\n"
     ]
    }
   ],
   "source": [
    "#coupon assignment: size of discount received by\n",
    "coup_data = np.zeros([n_cust, T, n_prod], dtype=np.float32)\n",
    "#product prices\n",
    "price_orig = np.zeros([n_prod,1])\n",
    "\n",
    "for j in range(n_prod):\n",
    "    price_orig[j] = np.median(prices[(prods == j) & (advertised == False)])\n",
    "\n",
    "for i in tqdm(range(n_cust)):\n",
    "        for t in range(T):\n",
    "            for j in np.arange(n_prod)[hist_data[i, t] == True]:\n",
    "                price = prices[(customers == i) & (times == t) & (prods == j)]\n",
    "                coup_data[i, t, j] = (price_orig[j]-price)/price_orig[j]\n",
    "\n",
    "np.savez(coup_path, data=coup_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will prepare the files for training and validation. I will save files as .pt to improve the performance of the DataLoader and not overload the memory usage of the computer. Let's start with the training and validation set preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data = np.load(hist_path)['data']\n",
    "coup_data = np.load(coup_path)['data']\n",
    "window_size = 10\n",
    "ovsize = 9\n",
    "#time ids for treat the weeks that we want to train\n",
    "time_ids = [np.arange(0, T)[i:i + window_size] for i in range(0, T, window_size - ovsize)]\n",
    "#product purchasing frequencies\n",
    "hist_data_inf = hist_data.mean(1)\n",
    "#lists definition\n",
    "coup_data_ = []\n",
    "hist_data_ = []\n",
    "hist_data_inf_ = []\n",
    "hist_data2 = []\n",
    "metas_i = []\n",
    "metas_t = []\n",
    "#load copuon assignment\n",
    "coup_data = np.load(coup_path)['data']\n",
    "#loop for fill the data (customers buys data (T & T+1) / coupon data (T & T+1) / purchasing frequencies / discounts\n",
    "for x, t_id in enumerate(time_ids):   \n",
    "    end_t = t_id[-1]\n",
    "    if end_t == T - 1: continue\n",
    "    for i in range(n_cust):     \n",
    "        coup_data_.append(coup_data[i, end_t])\n",
    "        hist_data_.append(hist_data[i, t_id].astype(np.int32))\n",
    "        hist_data_inf_.append(hist_data_inf[i])\n",
    "        hist_data2.append(hist_data[i, end_t+1].astype(np.int32))\n",
    "        metas_i.append(i)\n",
    "        metas_t.append(t_id)\n",
    "\n",
    "#save it on a dictionary\n",
    "data_train = {\n",
    "    'coup_data_': np.stack(coup_data_), #coup data +1\n",
    "    'hist_data' : np.stack(hist_data_),\n",
    "    'hist_data_inf' : np.stack(hist_data_inf_),\n",
    "    'hist_data2' : np.stack(hist_data2),#hist_data +1\n",
    "    'metas_i' : np.stack(metas_i),\n",
    "    'metas_t' : np.stack(metas_t)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makepath(desired_path, isfile = False):\n",
    "    '''\n",
    "    if the path does not exist make it\n",
    "    :param desired_path: can be path to a file or a folder name\n",
    "    :return:\n",
    "    '''\n",
    "    import os\n",
    "    if isfile:\n",
    "        if not os.path.exists(os.path.dirname(desired_path)):os.makedirs(os.path.dirname(desired_path))\n",
    "    else:\n",
    "        if not os.path.exists(desired_path): os.makedirs(desired_path)\n",
    "    return desired_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = len(hist_data2)\n",
    "np.random.seed(100)\n",
    "vald_ids = np.random.choice(n_data, int(n_data*0.1), replace=False)\n",
    "train_ids = list(set(range(n_data)).difference(set(vald_ids)))\n",
    "\n",
    "\n",
    "#save train data to .pkl\n",
    "path_output = makepath('output/train/hist_data.pt', isfile=True)\n",
    "for k, v in data_train.items():\n",
    "    torch.save(torch.tensor(v[train_ids]), path_output.replace('hist_data.pt', '%s.pt'%k))\n",
    "\n",
    "#save validation data to .pkl\n",
    "path_output = makepath('output/validation/hist_data.pt', isfile=True)\n",
    "for k, v in data_train.items():\n",
    "    torch.save(torch.tensor(v[vald_ids]), path_output.replace('hist_data.pt', '%s.pt'%k))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perpare the testing data. The testing will be applied on the 50th week. The test set specifies discount on product 24. But it's an special case because it has never been discounted before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_example = pd.read_csv(\"data/csv/prediction_example.csv\").sort_values(['i','j'])\n",
    "promotion_schedule = pd.read_csv(\"data/csv/promotion_schedule.csv\").sort_values(['j'])\n",
    "\n",
    "test_coup_data_ = []\n",
    "test_hist_data_ = []\n",
    "test_hist_data_inf_ = []\n",
    "test_hist_data2 = []\n",
    "test_metas_i = []\n",
    "\n",
    "current_coupon = np.zeros(n_prod)\n",
    "\n",
    "for j in range(n_prod):\n",
    "    discount = promotion_schedule.query('j == %d' % j).discount.to_numpy()\n",
    "    if len(discount) > 0: current_coupon[j] = discount\n",
    "\n",
    "T_test = 49\n",
    "t_ids = range(T_test-window_size, T_test)\n",
    "\n",
    "for i in list(set(prediction_example.i)):\n",
    "    test_coup_data_.append(current_coupon)\n",
    "    test_hist_data_.append(hist_data[i, t_ids].astype(np.int32))\n",
    "    test_hist_data_inf_.append(hist_data_inf[i])\n",
    "    test_hist_data2.append(prediction_example.query(\"i==%d\"%i).prediction.to_numpy())\n",
    "    test_metas_i.append(i)\n",
    "\n",
    "data_test = {\n",
    "    'coup_data_': np.stack(test_coup_data_), #coup data +1\n",
    "    'hist_data' : np.stack(test_hist_data_),\n",
    "    'hist_data_inf' : np.stack(test_hist_data_inf_),\n",
    "    'hist_data2' : np.stack(test_hist_data2),#hist_data +1\n",
    "    'metas_i' : np.stack(test_metas_i)\n",
    "}\n",
    "\n",
    "path_output = makepath(\"output/test/hist_data.pt\", isfile = True)\n",
    "for k, v in data_test.items():\n",
    "    torch.save(torch.tensor(v), path_output.replace('hist_data.pt', '%s.pt'%k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader\n",
    "I will create my own DataLoader. The main reason is because I will load the .pt files/dictionaries that I already prepared in the last step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "\n",
    "\n",
    "class SO1_DL(Dataset):\n",
    "    def __init__(self, dataset_dir):\n",
    "        self.ds = {}\n",
    "        for data_fname in glob.glob(os.path.join(dataset_dir, '*.pt')):\n",
    "            k = os.path.basename(data_fname).replace('.pt','')\n",
    "            self.ds[k] = torch.load(data_fname)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds['hist_data'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.fetch_data(idx)\n",
    "\n",
    "    def fetch_data(self, idx):\n",
    "        return {k: self.ds[k][idx].type(torch.float32) for k in self.ds.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling \n",
    "I will apply Deep Learning for this task. My model have a convolutional layer that will generate a feature map for customer purchases. Also I will apply an activation function to this layer. Hopefully, the filters of the convolution will extract patterns on the historic data of the customer and would be able to make relations between consumer-products buys. Also I add some linear bottlenecks to help share information. I use those because of my past experience using Mobilenetv2 which apply this technique (https://arxiv.org/pdf/1801.04381.pdf). Then, I will use a softmax layer to predict the probability of a customers buying a product in a concrete week (goal of the task).\n",
    "\n",
    "The number of neurons/filters have been benchmarket to see which combination works better. The final network is the one that gave me less loss and performed better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SO1MODEL(\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (ll): LeakyReLU(negative_slope=0.2)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (histdat_conv1): Conv1d(10, 20, kernel_size=(1,), stride=(1,))\n",
       "  (histdat_dense1): Linear(in_features=800, out_features=6, bias=False)\n",
       "  (coupdat_dense1): Linear(in_features=40, out_features=1, bias=False)\n",
       "  (hisdatinf_dense1): Linear(in_features=40, out_features=1, bias=False)\n",
       "  (ztp1_dense1): Linear(in_features=1760, out_features=40, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "class SO1MODEL(nn.Module):\n",
    "\n",
    "    def __init__(self, window_size=10, n_class=40, n_neurons=256, **kwargs):\n",
    "        super(SO1MODEL, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.1, inplace=False)\n",
    "        self.ll = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        H = 20\n",
    "        L = 1\n",
    "        self.histdat_conv1 = nn.Conv1d(window_size, H, 1, stride=1)\n",
    "        self.histdat_dense1 = nn.Linear(n_class*H, 6, bias=False)\n",
    "\n",
    "        self.coupdat_dense1 = nn.Linear(n_class, L, bias=False)\n",
    "        self.hisdatinf_dense1 = nn.Linear(n_class, L, bias=False)\n",
    "        self.ztp1_dense1 = nn.Linear(n_class* (2*H+4), n_class, bias=False) \n",
    "\n",
    "    def forward(self, coup_data_, hist_data, hist_data_inf):\n",
    "\n",
    "        bs, window_size, J = hist_data.shape\n",
    "        #print(hist_data.shape)\n",
    "        #convolucio\n",
    "        bh_out = self.ll(self.histdat_conv1(hist_data)).transpose(1,2).contiguous()\n",
    "        #bottleneck!\n",
    "        #linear1 in: sortida de conv (64,800)\n",
    "        bh_bar_out = self.ll(self.histdat_dense1(bh_out.view(bs, -1)))\n",
    "        #linear1 out: (64, 6) | multiply: weights linear1 (800,6) · linear1 out T: (6,64) \n",
    "        bh_bar_out = self.ll(torch.matmul(self.histdat_dense1.weight.transpose(0,1), bh_bar_out.transpose(0,1)).transpose(0,1)).view(bs, J, -1)\n",
    "        #multi out = 64,40,20\n",
    "        \n",
    "        #bottleneck!!\n",
    "        #linear2: in coup_data (64,40)\n",
    "        coup_out = self.ll(self.coupdat_dense1(coup_data_.view(bs, -1)))\n",
    "        #linear2: (64,1) | multiply: weights linear2 (40,1) · linear2 out (1,64)\n",
    "        coup_out = self.sigmoid(torch.matmul(self.coupdat_dense1.weight.transpose(0,1), coup_out.transpose(0,1))).transpose(0,1).view(bs, J, 1)\n",
    "        #multi out = 64,40,1      \n",
    "        hisdatinf_out = self.ll(self.hisdatinf_dense1(hist_data_inf.view(bs, -1)))\n",
    "        hisdatinf_out = self.sigmoid(torch.matmul(self.hisdatinf_dense1.weight.transpose(0,1), hisdatinf_out.transpose(0,1))).transpose(0,1).view(bs, J, 1)\n",
    "        \n",
    "        Z = torch.cat([bh_out, bh_bar_out,coup_data_.view([bs,J,1]), coup_out,hist_data_inf.view(bs, J, 1), hisdatinf_out  ], dim=-1)\n",
    "        #Z: (64,40,44)\n",
    "        \n",
    "        Ztp1 = self.ztp1_dense1(Z.view(bs,-1))\n",
    "        #Ztp1: (64,40)\n",
    "        pvalue = self.sigmoid(Ztp1)\n",
    "        result = {'hist_data2': pvalue}\n",
    "\n",
    "        return result\n",
    "\n",
    "model = SO1MODEL()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training part\n",
    "This class have all the functions needed to perform the training part. I also use a configuration dictionary to select the parameters for the training. I use a binary cross-entropy loss (BCE), Adam optimizer and in the end I print the training/validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SO1_Trainer:\n",
    "    \n",
    "    def __init__(self, work_dir, ps):\n",
    "        \n",
    "        #seed the RNG for all devices (CPU & GPU)\n",
    "        torch.manual_seed(ps.seed)\n",
    "        #time training control\n",
    "        starttime = datetime.now().replace(microsecond=0)\n",
    "        #create directory\n",
    "        ps.work_dir = makepath(work_dir, isfile = False)\n",
    "        #logger\n",
    "        print(\"|{}| Start training SO1 Model\".format(ps.exp_id))\n",
    "        kwargs = {'num_workers': ps.n_workers}\n",
    "        #load dataloaders\n",
    "        #training set\n",
    "        ds_train = SO1_DL(dataset_dir=os.path.join(ps.dataset_dir, 'train'))\n",
    "        self.ds_train = DataLoader(ds_train, batch_size=ps.batch_size, shuffle=True, drop_last=True, **kwargs)\n",
    "        #validation set\n",
    "        ds_val = SO1_DL(dataset_dir=os.path.join(ps.dataset_dir, 'validation'))\n",
    "        self.ds_val = DataLoader(ds_val, batch_size=ps.batch_size, shuffle=True, drop_last=True, **kwargs)\n",
    "        #test set\n",
    "        ds_test = SO1_DL(dataset_dir=os.path.join(ps.dataset_dir, 'test'))\n",
    "        self.ds_test = DataLoader(ds_test, batch_size=ps.batch_size, shuffle=True, drop_last=False)\n",
    "        #print dataset sizes\n",
    "        print(\"Dataset train size: {} validation size {} test size {}\".format(\n",
    "                                         len(self.ds_train.dataset),\n",
    "                                         len(self.ds_val.dataset) ,\n",
    "                                         len(self.ds_test.dataset)))\n",
    "        \n",
    "        #define the model\n",
    "        self.so1_model = SO1MODEL(window_size=ps.window_size, n_class=ps.n_class)\n",
    "        varlist = [var[1] for var in self.so1_model.named_parameters()]\n",
    "        #optimizer\n",
    "        self.optimizer = optim.Adam(varlist, lr=ps.base_lr, weight_decay=ps.reg_coef)\n",
    "        #loss and verboses\n",
    "        self.best_loss_total = np.inf\n",
    "        self.epochs_completed = 0\n",
    "        self.ps = ps\n",
    "        #binary cross entropy\n",
    "        self.BCELoss = nn.BCELoss()\n",
    "        \n",
    "    def _get_model(self):\n",
    "        return self.so1_model.module\n",
    "    \n",
    "    def train(self):\n",
    "        self.so1_model.train()\n",
    "        save_every_it = len(self.ds_train) / self.ps.log_every_epoch\n",
    "        train_loss_dict = {}\n",
    "        for it, dorig in enumerate(self.ds_train):\n",
    "            \n",
    "            dorig = {k:dorig[k] for k in dorig.keys()}\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            drec = self.so1_model(coup_data_=dorig['coup_data_'], hist_data=dorig['hist_data'], hist_data_inf=dorig['hist_data_inf'])\n",
    "\n",
    "            loss_total, cur_loss_dict = self.compute_loss(dorig, drec)\n",
    "            loss_total.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            train_loss_dict = {k: train_loss_dict.get(k, 0.0) + v.item() for k, v in cur_loss_dict.items()}\n",
    "            cur_train_loss_dict = {k: v / (it + 1) for k, v in train_loss_dict.items()}\n",
    "            train_msg = SO1_Trainer.creat_loss_message(cur_train_loss_dict, exp_id=self.ps.exp_id,\n",
    "                                                              epoch_num=self.epochs_completed, it=it, mode='train')\n",
    "\n",
    "           \n",
    "        print(train_msg)\n",
    "        train_loss_dict = {k: v / len(self.ds_train) for k, v in train_loss_dict.items()}\n",
    "        return train_loss_dict\n",
    "    \n",
    "    def evaluate(self, split_name='validation'):\n",
    "        self.so1_model.eval()\n",
    "        eval_loss_dict = {}\n",
    "        data = self.ds_val if split_name == 'validation' else self.ds_test\n",
    "        with torch.no_grad():\n",
    "            for dorig in data:\n",
    "                dorig = {k: dorig[k] for k in dorig.keys()}\n",
    "                drec = self.so1_model(coup_data_=dorig['coup_data_'], hist_data=dorig['hist_data'], hist_data_inf=dorig['hist_data_inf'])\n",
    "                _, cur_loss_dict = self.compute_loss(dorig, drec)\n",
    "\n",
    "                eval_loss_dict = {k: eval_loss_dict.get(k, 0.0) + v.item() for k, v in cur_loss_dict.items()}\n",
    "\n",
    "        eval_loss_dict = {k: v / len(data) for k, v in eval_loss_dict.items()}\n",
    "        return eval_loss_dict\n",
    "    \n",
    "    def compute_loss(self, dorig, drec):\n",
    "\n",
    "        loss_dict = {\n",
    "            'BCE': self.BCELoss(drec['hist_data2'], dorig['hist_data2']),\n",
    "            }\n",
    "\n",
    "        loss_dict['loss_total'] = torch.stack(list(loss_dict.values())).sum()\n",
    "\n",
    "        return loss_dict['loss_total'], loss_dict\n",
    "    \n",
    "    \n",
    "    def do_training(self, num_epochs=None, message=None):\n",
    "        starttime = datetime.now().replace(microsecond=0)\n",
    "        if num_epochs is None: num_epochs = self.ps.num_epochs\n",
    "        \n",
    "        prev_lr = np.inf\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min', patience=7)\n",
    "        \n",
    "        self.train_loss_list = []\n",
    "        self.eval_loss_list = []\n",
    "        \n",
    "        for epoch_num in range(1, num_epochs + 1):\n",
    "            train_loss_dict = self.train()\n",
    "            eval_loss_dict = self.evaluate()\n",
    "            \n",
    "            self.train_loss_list.append(train_loss_dict['loss_total'])\n",
    "            self.eval_loss_list.append(eval_loss_dict['loss_total'])\n",
    "            \n",
    "            scheduler.step(eval_loss_dict['loss_total'])\n",
    "            cur_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            if cur_lr != prev_lr:\n",
    "                print('--- Optimizer learning rate changed from %.2e to %.2e ---' % (prev_lr, cur_lr))\n",
    "                prev_lr = cur_lr\n",
    "            self.epochs_completed += 1\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                eval_msg = SO1_Trainer.creat_loss_message(eval_loss_dict, exp_id=self.ps.exp_id,\n",
    "                                                              epoch_num=epoch_num-1, it=len(self.ds_val),\n",
    "                                                               mode='valid')\n",
    "                \n",
    "                if eval_loss_dict['loss_total'] < self.best_loss_total:\n",
    "                    self.ps.best_model_fname = makepath(os.path.join(self.ps.work_dir, 'snapshots', 'SO1_E%03d.pt' % (\n",
    "                            self.epochs_completed)), isfile=True)\n",
    "                    print(eval_msg + ' !! ')\n",
    "                    self.best_loss_total = eval_loss_dict['loss_total']\n",
    "                    torch.save(self.so1_model.module.state_dict() if isinstance(self.so1_model,\n",
    "                                                                                     torch.nn.DataParallel) else self.so1_model.state_dict(),\n",
    "                               self.ps.best_model_fname)\n",
    "\n",
    "                else:\n",
    "                    print(eval_msg)\n",
    "           \n",
    "        endtime = datetime.now().replace(microsecond=0)\n",
    "        np.savez('experiments/experiment1/train_losses.npz', data=self.train_loss_list)\n",
    "        np.savez('experiments/experiment1/val_losses.npz', data=self.eval_loss_list)\n",
    "        print('Training done in %s! Best val total loss achieved: %.2e\\n' % (endtime - starttime, self.best_loss_total))\n",
    "        \n",
    "    def show_train_val_loss(self, train_loss_list, eval_loss_list):\n",
    "        #X and Y axis inputs for Plotly graph.\n",
    "\n",
    "        plot_data = [\n",
    "              go.Scatter(\n",
    "              x=np.arange(len(train_loss_list)),\n",
    "              y=train_loss_list,\n",
    "              name= 'train_loss'\n",
    "          ),\n",
    "           go.Scatter(\n",
    "              x=np.arange(len(eval_loss_list)),\n",
    "              y=eval_loss_list,\n",
    "              name='val_loss'\n",
    "              )\n",
    "          ]\n",
    "        plot_layout = go.Layout(\n",
    "              title='Train-Val loss',\n",
    "                xaxis=go.layout.XAxis(\n",
    "                    title=go.layout.xaxis.Title(\n",
    "                    text='Epochs')\n",
    "                ),\n",
    "                yaxis=go.layout.YAxis(\n",
    "                title=go.layout.yaxis.Title(\n",
    "                text='Loss')\n",
    "                    )\n",
    "                )\n",
    "        fig = go.Figure(data=plot_data, layout=plot_layout)\n",
    "        pyoff.iplot(fig)\n",
    "    \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def creat_loss_message(loss_dict, exp_id='XX', epoch_num=0, it=0,  mode='valid'):\n",
    "        ext_msg = ' | '.join(['%s = %.2e' % (k, v) for k, v in loss_dict.items() if k != 'loss_total'])\n",
    "        return '[%s] Epoch %03d - %s: [%s]' % (\n",
    "                exp_id, epoch_num, mode, ext_msg)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|experiment1| Start training SO1 Model\n",
      "Dataset train size: 70200 validation size 7800 test size 3\n",
      "Batch size: 64 | Epochs: 100\n"
     ]
    }
   ],
   "source": [
    "exp_id = 'experiment1'\n",
    "work_dir = os.path.join(\"experiments\", exp_id)\n",
    "\n",
    "params = {\n",
    "        'seed': 2,\n",
    "        'window_size': 10,\n",
    "        'n_class': 40,\n",
    "        'n_neurons': 256,\n",
    "        'batch_size': 64, \n",
    "        'n_workers': 10,\n",
    "        'cuda_id': 0,\n",
    "        'use_multigpu':False,\n",
    "        'reg_coef': 5e-4,\n",
    "        'base_lr': 5e-3,\n",
    "        'best_model_fname': None,\n",
    "        'log_every_epoch': 2,\n",
    "        'exp_id': exp_id,\n",
    "        'work_dir': work_dir,\n",
    "        'num_epochs': 100,\n",
    "        'dataset_dir': 'output',\n",
    "    }\n",
    "\n",
    "#training definition\n",
    "supercap_trainer = SO1_Trainer(work_dir, ps=Configer(default_ps_fname=params, **params))\n",
    "#parameters\n",
    "ps = supercap_trainer.ps\n",
    "#training part\n",
    "print(\"Batch size: {} | Epochs: {}\".format(ps.batch_size, ps.num_epochs))\n",
    "#supercap_trainer.do_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "name": "train_loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.08671859106266477,
          0.08541816158940757,
          0.08533633871507036,
          0.08529059199385182,
          0.08525686845332928,
          0.08533733078434955,
          0.08531115126259027,
          0.08526863339255109,
          0.08525857771576865,
          0.08524588443828325,
          0.08529284127382901,
          0.08519529132852263,
          0.08521929372741031,
          0.0852893618390943,
          0.0852805029220172,
          0.08524155548100706,
          0.08532744227317128,
          0.0852821104085739,
          0.08528032387695174,
          0.08390536453289381,
          0.08390921848506605,
          0.08390004901609717,
          0.0839109833549409,
          0.08391104400647383,
          0.08390061512766202,
          0.08390580242785224,
          0.08390012627848199,
          0.08390809892996276,
          0.08391610890912422,
          0.08390895169853729,
          0.08389615988440431,
          0.083925209076137,
          0.08392228941045647,
          0.08391369949604799,
          0.08375263582221674,
          0.08372781864523779,
          0.08372271140819809,
          0.08372614707756978,
          0.08372416510416643,
          0.0837251080206874,
          0.0837189503741471,
          0.08374103818455861,
          0.08372745110592159,
          0.08373288075731945,
          0.083717169804349,
          0.08372155236025905,
          0.0837222744275673,
          0.08371752882580252,
          0.08373207209740569,
          0.08372081551075417,
          0.08370314960972998,
          0.08369902137626153,
          0.083715559139739,
          0.08370745429823542,
          0.08370533823817425,
          0.08370407566047498,
          0.08369149732994881,
          0.0836957679402056,
          0.08370500808432155,
          0.0837069336107395,
          0.0837090390897526,
          0.08369712259307721,
          0.0836979917991553,
          0.083702135457229,
          0.08370047181939883,
          0.08370397755889779,
          0.08370896767362626,
          0.08369860686973607,
          0.08370776260679547,
          0.08369048615835988,
          0.08371075363081955,
          0.08370481315918647,
          0.08369738555574505,
          0.08370268277579197,
          0.08369294060802046,
          0.08370888963967127,
          0.08370568518982316,
          0.08370521733618892,
          0.08369979335090322,
          0.0836965228893189,
          0.08370857357462175,
          0.0837021020961667,
          0.08371258352672423,
          0.08368731468888747,
          0.08371584185392317,
          0.08369613389899261,
          0.08369395478091536,
          0.08369700495751888,
          0.08369249762477775,
          0.0836978571856544,
          0.08370501517121048,
          0.08369096325384114,
          0.08371046470668521,
          0.08371176208321848,
          0.08369965592643967,
          0.08371490811126946,
          0.0837133365316167,
          0.08370228062118709,
          0.08371112968799842,
          0.08370137141582414
         ]
        },
        {
         "name": "val_loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.08565727830672067,
          0.08545701535156935,
          0.08508648563268756,
          0.08557885638938463,
          0.0853506672727175,
          0.08540484343062747,
          0.08518237392764447,
          0.08521672824690164,
          0.08589005956718744,
          0.0853850904328764,
          0.08438783650063286,
          0.0858129853428888,
          0.08585782533834789,
          0.08543242458715912,
          0.08597602836849276,
          0.08503489528805756,
          0.08520821063232815,
          0.08501239022440162,
          0.08493742457598694,
          0.08417231090797865,
          0.08428801553062171,
          0.08412393428816282,
          0.0843093470662586,
          0.08397782378452869,
          0.0840783730026119,
          0.0839475270760946,
          0.08403841880234805,
          0.08417993396028015,
          0.08396328477696939,
          0.08412089654483086,
          0.08404828934383786,
          0.08409929842003121,
          0.08396110228024238,
          0.0842782403073035,
          0.08383660233956723,
          0.08402550608412293,
          0.08395483443313394,
          0.08393749154426834,
          0.0838959464295344,
          0.08397902031082752,
          0.08385394741434696,
          0.08369460628052389,
          0.08376818692142313,
          0.08391999594928805,
          0.08386003152151739,
          0.08378200232982635,
          0.08384216373616998,
          0.08386899863392853,
          0.08400384706160254,
          0.08388611360276041,
          0.08391589326553109,
          0.08388711376623674,
          0.08393560091326059,
          0.08382115171344812,
          0.08375593859794711,
          0.08395162551117337,
          0.08385011332094176,
          0.08382128548523611,
          0.08389604257896913,
          0.08375565045751816,
          0.08389138725917202,
          0.08382483627185348,
          0.08396617489412797,
          0.08392819626764818,
          0.08393054738763936,
          0.08381866374291665,
          0.08394127807095031,
          0.0839634213812095,
          0.08384450709770534,
          0.08384805714542215,
          0.08377115680905413,
          0.08387724741185007,
          0.08400959219814332,
          0.08391356240373013,
          0.08382566359417498,
          0.08390970140202972,
          0.08385863878633365,
          0.08388275332933615,
          0.08387513834336573,
          0.08377665108885647,
          0.08388272808356718,
          0.08369690737078998,
          0.08380352915072244,
          0.08399983236858667,
          0.08390738273208792,
          0.08378698953912278,
          0.08377488031367625,
          0.08378106605046051,
          0.08378979539083055,
          0.08383043639916034,
          0.0838881985030391,
          0.08372633411618303,
          0.08393625637962798,
          0.08390310111124653,
          0.08390137965767837,
          0.0838847479298095,
          0.08382693755109448,
          0.08386025466948502,
          0.0838326072582036,
          0.08389102667570114
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Train-Val loss"
        },
        "xaxis": {
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"7fe60a99-c9e7-4b3f-9d8e-66570ca0817d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"7fe60a99-c9e7-4b3f-9d8e-66570ca0817d\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '7fe60a99-c9e7-4b3f-9d8e-66570ca0817d',\n",
       "                        [{\"name\": \"train_loss\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"y\": [0.08671859106266477, 0.08541816158940757, 0.08533633871507036, 0.08529059199385182, 0.08525686845332928, 0.08533733078434955, 0.08531115126259027, 0.08526863339255109, 0.08525857771576865, 0.08524588443828325, 0.08529284127382901, 0.08519529132852263, 0.08521929372741031, 0.0852893618390943, 0.0852805029220172, 0.08524155548100706, 0.08532744227317128, 0.0852821104085739, 0.08528032387695174, 0.08390536453289381, 0.08390921848506605, 0.08390004901609717, 0.0839109833549409, 0.08391104400647383, 0.08390061512766202, 0.08390580242785224, 0.08390012627848199, 0.08390809892996276, 0.08391610890912422, 0.08390895169853729, 0.08389615988440431, 0.083925209076137, 0.08392228941045647, 0.08391369949604799, 0.08375263582221674, 0.08372781864523779, 0.08372271140819809, 0.08372614707756978, 0.08372416510416643, 0.0837251080206874, 0.0837189503741471, 0.08374103818455861, 0.08372745110592159, 0.08373288075731945, 0.083717169804349, 0.08372155236025905, 0.0837222744275673, 0.08371752882580252, 0.08373207209740569, 0.08372081551075417, 0.08370314960972998, 0.08369902137626153, 0.083715559139739, 0.08370745429823542, 0.08370533823817425, 0.08370407566047498, 0.08369149732994881, 0.0836957679402056, 0.08370500808432155, 0.0837069336107395, 0.0837090390897526, 0.08369712259307721, 0.0836979917991553, 0.083702135457229, 0.08370047181939883, 0.08370397755889779, 0.08370896767362626, 0.08369860686973607, 0.08370776260679547, 0.08369048615835988, 0.08371075363081955, 0.08370481315918647, 0.08369738555574505, 0.08370268277579197, 0.08369294060802046, 0.08370888963967127, 0.08370568518982316, 0.08370521733618892, 0.08369979335090322, 0.0836965228893189, 0.08370857357462175, 0.0837021020961667, 0.08371258352672423, 0.08368731468888747, 0.08371584185392317, 0.08369613389899261, 0.08369395478091536, 0.08369700495751888, 0.08369249762477775, 0.0836978571856544, 0.08370501517121048, 0.08369096325384114, 0.08371046470668521, 0.08371176208321848, 0.08369965592643967, 0.08371490811126946, 0.0837133365316167, 0.08370228062118709, 0.08371112968799842, 0.08370137141582414]}, {\"name\": \"val_loss\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"y\": [0.08565727830672067, 0.08545701535156935, 0.08508648563268756, 0.08557885638938463, 0.0853506672727175, 0.08540484343062747, 0.08518237392764447, 0.08521672824690164, 0.08589005956718744, 0.0853850904328764, 0.08438783650063286, 0.0858129853428888, 0.08585782533834789, 0.08543242458715912, 0.08597602836849276, 0.08503489528805756, 0.08520821063232815, 0.08501239022440162, 0.08493742457598694, 0.08417231090797865, 0.08428801553062171, 0.08412393428816282, 0.0843093470662586, 0.08397782378452869, 0.0840783730026119, 0.0839475270760946, 0.08403841880234805, 0.08417993396028015, 0.08396328477696939, 0.08412089654483086, 0.08404828934383786, 0.08409929842003121, 0.08396110228024238, 0.0842782403073035, 0.08383660233956723, 0.08402550608412293, 0.08395483443313394, 0.08393749154426834, 0.0838959464295344, 0.08397902031082752, 0.08385394741434696, 0.08369460628052389, 0.08376818692142313, 0.08391999594928805, 0.08386003152151739, 0.08378200232982635, 0.08384216373616998, 0.08386899863392853, 0.08400384706160254, 0.08388611360276041, 0.08391589326553109, 0.08388711376623674, 0.08393560091326059, 0.08382115171344812, 0.08375593859794711, 0.08395162551117337, 0.08385011332094176, 0.08382128548523611, 0.08389604257896913, 0.08375565045751816, 0.08389138725917202, 0.08382483627185348, 0.08396617489412797, 0.08392819626764818, 0.08393054738763936, 0.08381866374291665, 0.08394127807095031, 0.0839634213812095, 0.08384450709770534, 0.08384805714542215, 0.08377115680905413, 0.08387724741185007, 0.08400959219814332, 0.08391356240373013, 0.08382566359417498, 0.08390970140202972, 0.08385863878633365, 0.08388275332933615, 0.08387513834336573, 0.08377665108885647, 0.08388272808356718, 0.08369690737078998, 0.08380352915072244, 0.08399983236858667, 0.08390738273208792, 0.08378698953912278, 0.08377488031367625, 0.08378106605046051, 0.08378979539083055, 0.08383043639916034, 0.0838881985030391, 0.08372633411618303, 0.08393625637962798, 0.08390310111124653, 0.08390137965767837, 0.0838847479298095, 0.08382693755109448, 0.08386025466948502, 0.0838326072582036, 0.08389102667570114]}],\n",
       "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Train-Val loss\"}, \"xaxis\": {\"title\": {\"text\": \"Epochs\"}}, \"yaxis\": {\"title\": {\"text\": \"Loss\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7fe60a99-c9e7-4b3f-9d8e-66570ca0817d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print losses\n",
    "train_losses = np.load(os.path.join('experiments',exp_id,'train_losses.npz'))['data']\n",
    "eval_losses = np.load(os.path.join('experiments',exp_id,'val_losses.npz'))['data']\n",
    "supercap_trainer.show_train_val_loss(train_losses, eval_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluation of the algorithm using AUC metric as states the assignment. Note that I evaluate with the epoch that had lower loss (SO1_E042). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2c = lambda tensor: tensor.detach().cpu().numpy()\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc as compute_auc\n",
    "import json\n",
    "\n",
    "def evaluate_error(dataset_dir, so1_model, so1_ps, splitname, batch_size=1):\n",
    "    so1_model.eval()\n",
    "    n_class = 40\n",
    "    ds_name = dataset_dir\n",
    "    BCELoss = torch.nn.BCELoss()\n",
    "\n",
    "    ds = SO1_DL(dataset_dir=os.path.join(dataset_dir, splitname))\n",
    "    print('%s dataset size: %s'%(splitname,len(ds)))\n",
    "    ds = DataLoader(ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    all_auc = {}\n",
    "\n",
    "    loss_mean = []\n",
    "    with torch.no_grad():\n",
    "        for dorig in ds:\n",
    "            dorig = {k: dorig[k] for k in dorig.keys()}\n",
    "\n",
    "            drec = so1_model(coup_data_=dorig['coup_data_'], hist_data=dorig['hist_data'], hist_data_inf=dorig['hist_data_inf'])\n",
    "            loss_mean.append(BCELoss(drec['hist_data2'], dorig['hist_data2']))\n",
    "            \n",
    "            y_test = c2c(dorig['hist_data2'])\n",
    "            y_score = c2c(drec['hist_data2'])\n",
    "  \n",
    "            if splitname == 'test':\n",
    "                y_test = np.int32(y_test > 0.5)\n",
    "            # Compute ROC curve and ROC area for each class\n",
    "            for j in range(n_class):\n",
    "                fpr, tpr, _ = roc_curve(y_test[:, j], y_score[:, j])\n",
    "                auc = compute_auc(fpr, tpr)\n",
    "                c = all_auc.get(j, []); c.append(auc.mean()); all_auc[j] = c.copy()\n",
    "\n",
    "    valid_ids = {k: ~np.isnan(v) for k,v in all_auc.items()}\n",
    "    final_results = {\n",
    "        'BCE': float(c2c(torch.stack(loss_mean).mean())),\n",
    "        'auc': {k: np.mean(np.stack(v)[valid_ids[k]]) for k, v in all_auc.items()},\n",
    "    }\n",
    "\n",
    "    outpath = makepath(os.path.join(so1_ps.work_dir, 'evaluations', 'ds_%s'%ds_name, os.path.basename(so1_ps.best_model_fname).replace('.pt','_%s.json'%splitname)),isfile=True)\n",
    "    with open(outpath, 'w') as f:\n",
    "        json.dump(final_results,f)\n",
    "\n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configer import Configer\n",
    "\n",
    "\n",
    "def expid2model(expr_dir):\n",
    "    from configer import Configer\n",
    "\n",
    "    if not os.path.exists(expr_dir): raise ValueError('Could not find the experiment directory: %s' % expr_dir)\n",
    "\n",
    "    best_model_fname = sorted(glob.glob(os.path.join(expr_dir, 'snapshots', '*.pt')), key=os.path.getmtime)[-1]\n",
    "\n",
    "    print(('Found SO1 Trained Model: %s' % best_model_fname))\n",
    "    \n",
    "    default_ps_fname = glob.glob(os.path.join(expr_dir,'*.ini'))[0]\n",
    "    ps = Configer(default_ps_fname=default_ps_fname, work_dir = expr_dir, best_model_fname=best_model_fname)\n",
    "\n",
    "    return ps, best_model_fname\n",
    "\n",
    "def load_so1_model(expr_dir, so1_pt):\n",
    "\n",
    "    import importlib\n",
    "    import torch\n",
    "\n",
    "    ps, trained_model_fname = expid2model(expr_dir)\n",
    "    so1_pt.load_state_dict(torch.load(trained_model_fname, map_location='cpu'))\n",
    "    so1_pt.eval()\n",
    "    \n",
    "    return so1_pt, ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Found: [experiments/experiment1/snapshots/SO1_E042.pt] [Running on dataset: output] \n",
      "------- TRAIN ----------\n",
      "train dataset size: 70200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lupotto/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py:571: UndefinedMetricWarning:\n",
      "\n",
      "No positive samples in y_true, true positive value should be meaningless\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE = 8.37e-02\n",
      "AUC: 0: 0.55, 1: 0.62, 2: 0.59, 3: 0.59, 4: 0.54, 5: 0.69, 6: 0.64, 7: 0.60, 8: 0.53, 9: 0.53, 10: 0.53, 11: 0.53, 12: 0.51, 13: 0.53, 14: 0.53, 15: 0.63, 16: 0.56, 17: 0.53, 18: 0.49, 19: 0.47, 20: 0.50, 21: 0.54, 22: 0.54, 23: 0.52, 24: 0.56, 25: 0.54, 26: 0.53, 27: 0.55, 28: 0.52, 29: 0.49, 30: 0.70, 31: 0.47, 32: 0.51, 33: 0.68, 34: 0.61, 35: 0.53, 36: 0.55, 37: 0.50, 38: 0.49, 39: 0.72\n",
      "------- VALIDATION ----------\n",
      "validation dataset size: 7800\n",
      "BCE = 8.37e-02\n",
      "AUC: 0: 0.61, 1: 0.63, 2: 0.60, 3: 0.60, 4: 0.41, 5: 0.68, 6: 0.65, 7: 0.54, 8: 0.53, 9: 0.47, 10: 0.56, 11: 0.52, 12: 0.55, 13: 0.57, 14: 0.54, 15: 0.64, 16: 0.58, 17: 0.57, 18: 0.56, 19: 0.39, 20: 0.31, 21: 0.56, 22: 0.48, 23: 0.68, 24: 0.57, 25: 0.47, 26: 0.50, 27: 0.44, 28: 0.53, 29: 0.47, 30: 0.70, 31: 0.53, 32: 0.48, 33: 0.68, 34: 0.64, 35: 0.48, 36: 0.50, 37: 0.51, 38: 0.42, 39: 0.71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "expr_code = 'experiment1'\n",
    "\n",
    "trained_model_fname = 'SO1_E042.pt'\n",
    "expr_dir = os.path.join('experiments', expr_code, \"snapshots\", trained_model_fname)\n",
    "\n",
    "so1_model = SO1MODEL(window_size=ps.window_size, n_class=ps.n_class)\n",
    "so1_model.load_state_dict(torch.load(expr_dir, map_location='cpu'))\n",
    "\n",
    "so1_ps = supercap_trainer.ps\n",
    "so1_ps.best_model_fname = expr_dir\n",
    "so1_ps.dataset_dir = \"output\"\n",
    "\n",
    "\n",
    "dataset_dir = so1_ps.dataset_dir\n",
    "\n",
    "\n",
    "print('Model Found: [%s] [Running on dataset: %s] '%(so1_ps.best_model_fname, dataset_dir))\n",
    "for splitname in ['train', 'validation']:\n",
    "    print('------- %s ----------'%splitname.upper())\n",
    "    results = evaluate_error(dataset_dir, so1_model, so1_ps, splitname, batch_size=512)\n",
    "    print('BCE = %.2e' % (results['BCE']))\n",
    "    print('AUC: %s' % (', '.join(['%s: %.2f'%(k,v) for k, v in results['auc'].items()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on week 50th\n",
    "First, I create a ground truth csv consumers and products. Then I load the promotion schedule. And finally I make predictions on the 50th week. The last step is generate the predictions_results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create csv for predictions\n",
    "#id_consumer 0..1999\n",
    "#id_product 0..39\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('data/csv/prediction_ground_truth.csv','w') as f1:\n",
    "    writer=csv.writer(f1, delimiter=',',lineterminator='\\n',)\n",
    "    writer.writerow([\"i\",\"j\",\"prediction\"])\n",
    "    for i in range(0,2000):\n",
    "        for j in range(0,40):\n",
    "            row = [i,j]\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test will be applied on week 50th\n",
    "prediction_example = pd.read_csv(\"data/csv/prediction_ground_truth.csv\")  \n",
    "promotion_schedule = pd.read_csv(\"data/csv/promotion_schedule.csv\")  \n",
    "prediction_results = pd.DataFrame(columns=list(prediction_example.columns))\n",
    "\n",
    "current_coupon = np.zeros(n_prod)\n",
    "for j in range(n_prod):\n",
    "    discount = promotion_schedule.query('j == %d' % j).discount.to_numpy()\n",
    "    if len(discount) > 0: current_coupon[j] = discount\n",
    "\n",
    "    \n",
    "T_test = 49\n",
    "tIds = range(T_test - window_size, T_test)\n",
    "\n",
    "for d in prediction_example.iterrows():\n",
    "    i, j = int(d[1].i), int(d[1].j)\n",
    "    \n",
    "    \n",
    "    prediction = c2c(so1_model(\n",
    "        coup_data_=torch.tensor(current_coupon[np.newaxis], dtype=torch.float32),\n",
    "        hist_data=torch.tensor(hist_data[i, tIds][np.newaxis], dtype=torch.float32),\n",
    "        hist_data_inf=torch.tensor(hist_data_inf[i][np.newaxis], dtype=torch.float32))['hist_data2'])[0, j]\n",
    "        \n",
    "    prediction_results = prediction_results.append({'i': int(i), 'j': int(j), 'prediction': prediction}, ignore_index=True)\n",
    "\n",
    "prediction_results.to_csv(\"data/csv/prediction_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
